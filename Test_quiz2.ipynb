{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Quiz on Prompt Engineering \n",
    "Welcome to the quiz! Please answer the questions below and click 'Submit' to see your results. üß†‚úÖ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "# This is the quiz data, structured from the text file you provided.\n",
    "# Each item contains the question context, the specific question, the options, and the correct answer.\n",
    "quiz_data = [\n",
    "    {\n",
    "        'task': 'Task 1: Rewrite the following prompt to make it clearer, better structured, and with a specific instruction: ‚ÄúMake me test cases for the login page‚Äù',\n",
    "        'prompt_template': \"‚ÄúBased on the following User Story, '{0}' five functional test cases (both '{1}') for the login page...\"\",\n",
    "        'questions': [\n",
    "            {\n",
    "                'id': 1,\n",
    "                'options': ['Make', 'Rewrite', 'Generate'],\n",
    "                'correct': 'Generate'\n",
    "            },\n",
    "            {\n",
    "                'id': 2,\n",
    "                'options': ['positive and negative', 'new and old', 'good and bad'],\n",
    "                'correct': 'positive and negative'\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'task': 'Task 2: Create a prompt that asks GenAI to generate 3 test cases and return the result in a table format with specific columns.',\n",
    "        'prompt_template': \"\\\"Generate 3 functional '{0}' for the user login page. Please provide the '{1}' in table format with the following columns: ID, Test Title, Steps to Execute, Expected Result.\\\"\",\n",
    "        'questions': [\n",
    "            {\n",
    "                'id': 1,\n",
    "                'options': ['test objectives', 'test cases', 'use cases'],\n",
    "                'correct': 'test cases'\n",
    "            },\n",
    "            {\n",
    "                'id': 2,\n",
    "                'options': ['thoughts', 'output', 'ideas'],\n",
    "                'correct': 'output'\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'task': 'Task 3: Write a prompt that allows GenAI to compare two versions of a User Story for testability and clarity.',\n",
    "        'prompt_template': \"\\\"Analyze the following two User Story versions and indicate which one is clearer and more suitable for test case '{0}'. Explain your reasoning. '{1}' step by step.\\\"\",\n",
    "        'questions': [\n",
    "            {\n",
    "                'id': 1,\n",
    "                'options': ['ideas', 'vision', 'generation'],\n",
    "                'correct': 'generation'\n",
    "            },\n",
    "            {\n",
    "                'id': 2,\n",
    "                'options': ['Go', 'Run', 'Think'],\n",
    "                'correct': 'Think'\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'task': 'Task 4: Improve a weak prompt to make the request more specific and informative.',\n",
    "        'prompt_template': \"\\\"Instead of ‚ÄòWrite me test cases for my user story‚Äô, '{0}': ‚ÄòBased on the following User Story, generate 5 functional test cases in the '{1}': Title, Steps, Expected Result...‚Äô\\\"\",\n",
    "        'questions': [\n",
    "            {\n",
    "                'id': 1,\n",
    "                'options': ['use', 'remove', 'think'],\n",
    "                'correct': 'use'\n",
    "            },\n",
    "            {\n",
    "                'id': 2,\n",
    "                'options': ['section', 'format', 'prompt'],\n",
    "                'correct': 'format'\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'task': 'Task 5: Fill in the blanks to construct a complete prompt using the \\\"CRAFT\\\" framework.',\n",
    "        'prompt_template': \"Context: ...\\nRole: '{0}'\\nAction: Generate 5 functional test cases (both negative and positive)\\nFormat: '{1}'\\nTarget Audience: ...\",\n",
    "        'questions': [\n",
    "            {\n",
    "                'id': 1,\n",
    "                'options': ['You are a prompt engineer', 'You are a senior QC engineer (or ‚ÄúAct as a senior QC engineer‚Äù)', 'You are the best'],\n",
    "                'correct': 'You are a senior QC engineer (or ‚ÄúAct as a senior QC engineer‚Äù) '\n",
    "            },\n",
    "            {\n",
    "                'id': 2,\n",
    "                'options': ['Table (or tabular)', 'Interview', 'mp3'],\n",
    "                'correct': 'Table (or tabular)'\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# This will hold all the interactive radio button widgets\n",
    "all_question_widgets = []\n",
    "question_items = []\n",
    "\n",
    "# Dynamically create the widgets for each question\n",
    "for i, task_data in enumerate(quiz_data):\n",
    "    task_label = widgets.HTML(f\"<h3>{task_data['task']}</h3>\")\n",
    "    prompt_label = widgets.HTML(f\"<i>Prompt: {task_data['prompt_template'].replace('{0}', '<b>(1)</b>').replace('{1}', '<b>(2)</b>')}</i><hr>\")\n",
    "    \n",
    "    question_widgets = []\n",
    "    for q in task_data['questions']:\n",
    "        question_label = widgets.Label(value=f\"Question {q['id']}:\")\n",
    "        radio_buttons = widgets.RadioButtons(\n",
    "            options=q['options'],\n",
    "            description='',\n",
    "            disabled=False,\n",
    "            layout=widgets.Layout(width='max-content')\n",
    "        )\n",
    "        question_widgets.append(radio_buttons)\n",
    "        all_question_widgets.append({'widget': radio_buttons, 'correct': q['correct'], 'task_num': i + 1, 'q_num': q['id']})\n",
    "        \n",
    "    task_box = widgets.VBox([task_label, prompt_label, *question_widgets])\n",
    "    question_items.append(task_box)\n",
    "\n",
    "# Create the submit button\n",
    "submit_button = widgets.Button(\n",
    "    description='Submit Answers',\n",
    "    button_style='success', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Click to grade your answers',\n",
    "    icon='check'\n",
    ")\n",
    "\n",
    "# Create an output area to display the results\n",
    "results_output = widgets.Output()\n",
    "\n",
    "# This function runs when the submit button is clicked\n",
    "def check_answers(b):\n",
    "    score = 0\n",
    "    total_questions = len(all_question_widgets)\n",
    "    \n",
    "    with results_output:\n",
    "        clear_output(wait=True)\n",
    "        result_html = \"<h2>Quiz Results</h2>\"\n",
    "        for item in all_question_widgets:\n",
    "            widget = item['widget']\n",
    "            correct_answer = item['correct']\n",
    "            user_answer = widget.value\n",
    "            \n",
    "            result_html += f\"<b>Task {item['task_num']}, Question {item['q_num']}:</b> \"\n",
    "            if user_answer == correct_answer:\n",
    "                score += 1\n",
    "                result_html += f\"<span style='color:green;'>Correct!</span><br>\"\n",
    "            else:\n",
    "                result_html += f\"<span style='color:red;'>Incorrect.</span> Your answer: '{user_answer}'. Correct answer: '{correct_answer}'<br>\"\n",
    "        \n",
    "        final_score_percentage = (score / total_questions) * 100\n",
    "        result_html += f\"<hr><h3>Your final score is: {score}/{total_questions} ({final_score_percentage:.2f}%)</h3>\"\n",
    "        \n",
    "        if final_score_percentage == 100:\n",
    "            result_html += \"<p style='font-size:1.2em; color:blue;'>Excellent work! You aced it! üéâ</p>\"\n",
    "        elif final_score_percentage >= 75:\n",
    "             result_html += \"<p style='font-size:1.2em; color:green;'>Great job! You know your stuff. üëç</p>\"\n",
    "        else:\n",
    "             result_html += \"<p style='font-size:1.2em; color:orange;'>Good effort! Keep practicing. ü§ì</p>\"\n",
    "            \n",
    "        display(HTML(result_html))\n",
    "\n",
    "# Link the function to the button's on_click event\n",
    "submit_button.on_click(check_answers)\n",
    "\n",
    "# Display all the quiz elements\n",
    "quiz_layout = widgets.VBox(question_items)\n",
    "display(quiz_layout, submit_button, results_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
