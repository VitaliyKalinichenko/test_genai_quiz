{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ Week 2: GenAI Fundamentals & Tools Training\n",
    "\n",
    "**Duration:** 1 week  \n",
    "**Target Audience:** QC Engineers, TA & SET Engineers  \n",
    "**Format:** Self-paced learning with group activities\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this week, you will:\n",
    "\n",
    "‚úÖ **Deepen understanding** of LLMs, prompting, and GenAI foundations  \n",
    "‚úÖ **Gain overview** of key AI assistants and their capabilities  \n",
    "‚úÖ **Complete practical** prompting exercises  \n",
    "‚úÖ **Participate in** mid-week feedback and assessment call  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÖ Weekly Schedule Overview\n",
    "\n",
    "| Day | Activity | Duration | Focus |\n",
    "|-----|----------|----------|-------|\n",
    "| 1-2 | **Step 1:** Deepening the Basics | 2 days | LLMs, GenAI, Prompting Fundamentals |\n",
    "| 3-4 | **Step 2:** Tools Exploration | 2 days | AI Tools Comparison & Hands-on Practice |\n",
    "| 5 | **Step 3:** Mid-week Check-in Call | 45 min | Feedback, Q&A, Course Adjustment |\n",
    "| 6-7 | Practice & Consolidation | As needed | Review, Additional Exercises |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìö Step 1: Deepening the Basics\n",
    "\n",
    "**Duration:** 2 days  \n",
    "**Goal:** Build a clear understanding of what LLMs are, how GenAI works, and what prompting is\n",
    "\n",
    "## üéì Required Materials\n",
    "\n",
    "### Core Curricula (~6 hours total)\n",
    "\n",
    "1. **[Generative AI for QC Engineers Curriculum](https://softserve.csod.com/ui/lms-learning-details/app/curriculum/51c09d8d-82d0-4ae7-aa0f-b9bbf685bad6)**\n",
    "   - Duration: ~3 hours review\n",
    "   - Focus: QC-specific applications\n",
    "\n",
    "2. **[Generative AI for TA & SET Engineers Curriculum](https://softserve.csod.com/ui/lms-learning-details/app/curriculum/1a0ec61b-50ef-4278-be20-907e5e390270)**\n",
    "   - Duration: ~3 hours review\n",
    "   - Focus: Test automation applications\n",
    "\n",
    "### Specialized Resources (~3 hours total)\n",
    "\n",
    "3. **[GEN AI Prompting for Software Testers Handbook](https://softserveinc.sharepoint.com/sites/QualityManagementOffice/SitePages/AI-Prompting-for-Software-Testers.aspx)**\n",
    "   - Duration: ~2 hours\n",
    "   - **Key Focus:** Sections 5, 6, 7 (techniques and frameworks)\n",
    "\n",
    "4. **[Realize Your Potential: SoftServe Motivational](https://softserve.csod.com/LMS/Video/LaunchVideo.aspx?loid=6a00af4e-7b5d-41e2-9b77-2d02ebe47450)**\n",
    "   - Duration: ~1 hour\n",
    "   - Purpose: Motivation and mindset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíª Step 1 Activities\n",
    "\n",
    "### Activity 1.1: Individual Prompt Exercise\n",
    "\n",
    "**Tool:** PromptTrainer  \n",
    "**Duration:** 30-45 minutes  \n",
    "**Objective:** Practice basic prompt construction\n",
    "\n",
    "**Instructions:**\n",
    "1. Access PromptTrainer platform\n",
    "2. Complete at least 3 prompt improvement exercises\n",
    "3. Focus on clarity, specificity, and context\n",
    "\n",
    "### Activity 1.2: Group Discussion Call\n",
    "\n",
    "**Duration:** 60 minutes  \n",
    "**Format:** Interactive video call\n",
    "\n",
    "**Discussion Topics:**\n",
    "- ‚úÖ What makes a good prompt?\n",
    "- ‚úÖ Understanding different AI assistants\n",
    "- ‚úÖ Common prompting mistakes and how to avoid them\n",
    "- ‚úÖ Q&A session\n",
    "\n",
    "## üìù Step 1 Deliverables\n",
    "\n",
    "**Required Submissions:**\n",
    "- [ ] **Completed discussion call attendance** with all participants\n",
    "- [ ] **Submitted rewritten prompts** from PromptTrainer exercises\n",
    "- [ ] **Reflection notes** (2-3 key learnings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Self-Assessment Checklist\n",
    "# Run this cell and mark your progress\n",
    "\n",
    "print(\"üìã STEP 1 PROGRESS TRACKER\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "checklist = {\n",
    "    \"QC Engineers Curriculum Completed\": False,\n",
    "    \"TA & SET Engineers Curriculum Completed\": False,\n",
    "    \"Prompting Handbook Sections 5-7 Reviewed\": False,\n",
    "    \"Motivational Video Watched\": False,\n",
    "    \"PromptTrainer Exercises Completed\": False,\n",
    "    \"Group Discussion Call Attended\": False,\n",
    "    \"Prompts Submitted\": False\n",
    "}\n",
    "\n",
    "# Update these values as you complete each item\n",
    "for item, completed in checklist.items():\n",
    "    status = \"‚úÖ\" if completed else \"‚è≥\"\n",
    "    print(f\"{status} {item}\")\n",
    "\n",
    "completed_count = sum(checklist.values())\n",
    "total_count = len(checklist)\n",
    "progress_percentage = (completed_count / total_count) * 100\n",
    "\n",
    "print(f\"\\nüìä Overall Progress: {completed_count}/{total_count} ({progress_percentage:.1f}%)\")\n",
    "\n",
    "if progress_percentage == 100:\n",
    "    print(\"üéâ Congratulations! Step 1 completed successfully!\")\n",
    "elif progress_percentage >= 70:\n",
    "    print(\"üöÄ Great progress! You're almost there!\")\n",
    "else:\n",
    "    print(\"üí™ Keep going! You're building important skills!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üõ†Ô∏è Step 2: Tools Exploration\n",
    "\n",
    "**Duration:** 2 days  \n",
    "**Goal:** Understand current GenAI tools, how they differ, and when to use them\n",
    "\n",
    "## üé• Required Materials\n",
    "\n",
    "### Video Resources (~36 minutes total)\n",
    "\n",
    "1. **\"ChatGPT vs Claude vs Gemini: The Best AI for Each Use Case in 2025\"**\n",
    "   - Duration: ~21 minutes\n",
    "   - Focus: Tool comparison and use cases\n",
    "\n",
    "2. **\"Don't Waste Your Money: Which AI Upgrade Is ACTUALLY Worth It?\"**\n",
    "   - Duration: ~15 minutes\n",
    "   - Focus: Cost-benefit analysis\n",
    "\n",
    "### Documentation & Resources (~2.5 hours total)\n",
    "\n",
    "3. **LLMs - Comparison & Investigation.xlsx**\n",
    "   - Duration: ~30 minutes structured review\n",
    "   - Content: Detailed tool comparison matrix\n",
    "\n",
    "4. **Gen AI Productivity Boost - Toolset**\n",
    "   - Duration: ~30 minutes reading\n",
    "   - Focus: Productivity applications\n",
    "\n",
    "5. **Gen AI Productivity Boost - Task Library**\n",
    "   - Duration: ~30 minutes browsing\n",
    "   - Content: Real-world use cases\n",
    "\n",
    "6. **QMO Office365 Tools Research Docs**\n",
    "   - Duration: ~30-45 minutes\n",
    "   - Focus: Enterprise integration\n",
    "\n",
    "7. **Toolset Usage Policy**\n",
    "   - Duration: ~15-20 minutes\n",
    "   - **Critical:** Compliance and guidelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Step 2 Activities\n",
    "\n",
    "### Activity 2.1: Hands-on Tool Exercise\n",
    "\n",
    "**Format:** Group-based practical exercise  \n",
    "**Duration:** 1-2 hours\n",
    "\n",
    "**Instructions:**\n",
    "1. **Form groups** (3-4 people per group)\n",
    "2. **Select a tool** from the comparison matrix\n",
    "3. **Choose a use case** from the Use Case Library\n",
    "4. **Write one practical prompt** for your selected tool and use case\n",
    "5. **Test and refine** the prompt\n",
    "6. **Document results** and lessons learned\n",
    "\n",
    "### Activity 2.2: Policy Review Session\n",
    "\n",
    "**Duration:** 30 minutes  \n",
    "**Objective:** Understand compliance requirements\n",
    "\n",
    "**Tasks:**\n",
    "- Review Toolset Usage Policy thoroughly\n",
    "- Identify key takeaways and restrictions\n",
    "- Note any questions for clarification\n",
    "\n",
    "## üìã Step 2 Deliverables\n",
    "\n",
    "**Required Submissions:**\n",
    "- [ ] **Tool comparison summary** (understanding of different AI tools)\n",
    "- [ ] **Practical prompt example** (demonstrated prompting ability)\n",
    "- [ ] **Policy compliance notes** (key concerns and guidelines documented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Tool Comparison Matrix Template\n",
    "# Use this to organize your tool research findings\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create a comparison framework\n",
    "tools_comparison = {\n",
    "    'Tool': ['ChatGPT', 'Claude', 'Gemini', 'Copilot', 'Other'],\n",
    "    'Best Use Cases': ['', '', '', '', ''],\n",
    "    'Strengths': ['', '', '', '', ''],\n",
    "    'Limitations': ['', '', '', '', ''],\n",
    "    'Cost Model': ['', '', '', '', ''],\n",
    "    'Integration': ['', '', '', '', ''],\n",
    "    'Testing Applications': ['', '', '', '', '']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(tools_comparison)\n",
    "print(\"üîß AI Tools Comparison Matrix Template\")\n",
    "print(\"=\" * 50)\n",
    "print(df.to_string(index=False))\n",
    "print(\"\\nüìù Fill in this matrix as you research each tool!\")\n",
    "print(\"üí° Tip: Focus on testing-specific applications and use cases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Prompt Development Template\n",
    "# Use this template for your hands-on exercise\n",
    "\n",
    "prompt_template = {\n",
    "    \"Selected Tool\": \"\",  # e.g., \"ChatGPT-4\"\n",
    "    \"Use Case Category\": \"\",  # e.g., \"Test Case Generation\"\n",
    "    \"Specific Scenario\": \"\",  # e.g., \"API testing for e-commerce checkout\"\n",
    "    \"Initial Prompt\": \"\",  # Your first attempt\n",
    "    \"Refined Prompt\": \"\",  # Improved version\n",
    "    \"Results Quality\": \"\",  # Rate 1-10 and explain\n",
    "    \"Lessons Learned\": \"\",  # What worked/didn't work\n",
    "    \"Policy Considerations\": \"\"  # Any compliance notes\n",
    "}\n",
    "\n",
    "print(\"üìù PROMPT DEVELOPMENT WORKSHEET\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for key, value in prompt_template.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "print(\"\\nüí° Instructions:\")\n",
    "print(\"1. Fill in each section as you work through the exercise\")\n",
    "print(\"2. Test both initial and refined prompts\")\n",
    "print(\"3. Document specific improvements made\")\n",
    "print(\"4. Note any policy or compliance considerations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üìû Step 3: Mid-week Check-in Call\n",
    "\n",
    "**Duration:** ~45 minutes (Day 5)  \n",
    "**Goal:** Sync with all participants, gather feedback, discuss difficulties, adjust approach if needed\n",
    "\n",
    "## üìã Call Format\n",
    "\n",
    "### Structure\n",
    "- **Platform:** Zoom/MS Teams\n",
    "- **Format:** Open Q&A and structured discussion\n",
    "- **Attendance:** All participants required\n",
    "\n",
    "### Agenda\n",
    "\n",
    "1. **Welcome & Check-in** (5 minutes)\n",
    "   - Quick roll call\n",
    "   - Overall sentiment check\n",
    "\n",
    "2. **Individual Reflections** (15 minutes)\n",
    "   - Each participant shares 2-3 bullet points on how their understanding has changed\n",
    "   - Key \"aha\" moments or challenges\n",
    "\n",
    "3. **Group Discussion on Tool Differences** (15 minutes)\n",
    "   - Compare findings from tool exploration\n",
    "   - Discuss practical applications\n",
    "   - Share successful prompts\n",
    "\n",
    "4. **Q&A and Problem Solving** (8 minutes)\n",
    "   - Address specific challenges\n",
    "   - Clarify concepts\n",
    "   - Policy questions\n",
    "\n",
    "5. **Next Steps and Adjustments** (2 minutes)\n",
    "   - Confirm remaining week activities\n",
    "   - Any course corrections needed\n",
    "\n",
    "## üìù Call Deliverables\n",
    "\n",
    "**Required Outcomes:**\n",
    "- [ ] **Meeting notes** documenting key discussion points\n",
    "- [ ] **Feedback summary** from all participants\n",
    "- [ ] **Action items** for remaining week\n",
    "- [ ] **Course adjustments** (if needed) based on group needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mid-week Check-in Preparation\n",
    "# Complete this before the call\n",
    "\n",
    "print(\"üìû MID-WEEK CHECK-IN PREPARATION\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "reflection_prompts = [\n",
    "    \"What was your biggest 'aha' moment this week?\",\n",
    "    \"Which concept or tool surprised you the most?\",\n",
    "    \"What challenge did you face, and how did you overcome it?\",\n",
    "    \"How has your understanding of AI tools changed?\",\n",
    "    \"What practical application excites you most?\",\n",
    "    \"What policy or compliance concern do you have?\"\n",
    "]\n",
    "\n",
    "print(\"ü§î REFLECTION QUESTIONS\")\n",
    "print(\"Prepare 2-3 bullet points for each relevant question:\\n\")\n",
    "\n",
    "for i, prompt in enumerate(reflection_prompts, 1):\n",
    "    print(f\"{i}. {prompt}\")\n",
    "    print(\"   ‚Ä¢ Your answer: \")\n",
    "    print(\"   ‚Ä¢ \")\n",
    "    print(\"   ‚Ä¢ \")\n",
    "    print()\n",
    "\n",
    "print(\"üìã QUESTIONS FOR THE GROUP\")\n",
    "print(\"Prepare any specific questions you'd like to discuss:\")\n",
    "print(\"‚Ä¢ \")\n",
    "print(\"‚Ä¢ \")\n",
    "print(\"‚Ä¢ \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üìä Week 2 Summary & Assessment\n",
    "\n",
    "## üéØ Expected Outcomes\n",
    "\n",
    "By the end of Week 2, participants should demonstrate:\n",
    "\n",
    "### Knowledge & Understanding\n",
    "- ‚úÖ **Solid foundation** in LLM fundamentals\n",
    "- ‚úÖ **Clear understanding** of how different AI tools work\n",
    "- ‚úÖ **Awareness** of appropriate use cases for each tool\n",
    "\n",
    "### Practical Skills\n",
    "- ‚úÖ **Practical prompting abilities** with demonstrated improvement\n",
    "- ‚úÖ **Tool selection skills** based on task requirements\n",
    "- ‚úÖ **Basic prompt engineering** techniques\n",
    "\n",
    "### Compliance & Best Practices\n",
    "- ‚úÖ **Familiarity** with major AI tools and their capabilities\n",
    "- ‚úÖ **Clear understanding** of usage policies and best practices\n",
    "- ‚úÖ **Policy compliance awareness** and guidelines\n",
    "\n",
    "## üìà Success Metrics\n",
    "\n",
    "- **Participation:** 100% attendance in group activities\n",
    "- **Engagement:** Active contribution to discussions\n",
    "- **Skill Development:** Demonstrable improvement in prompt quality\n",
    "- **Knowledge Application:** Successful completion of practical exercises\n",
    "- **Policy Understanding:** Clear articulation of compliance requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Week 2 Final Assessment\n",
    "# Complete this at the end of the week\n",
    "\n",
    "print(\"üèÜ WEEK 2 FINAL SELF-ASSESSMENT\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Self-assessment categories\n",
    "assessment_areas = {\n",
    "    \"LLM Fundamentals Understanding\": 0,  # Rate 1-10\n",
    "    \"AI Tools Knowledge\": 0,  # Rate 1-10\n",
    "    \"Prompt Writing Skills\": 0,  # Rate 1-10\n",
    "    \"Tool Selection Ability\": 0,  # Rate 1-10\n",
    "    \"Policy Compliance Understanding\": 0,  # Rate 1-10\n",
    "    \"Practical Application Confidence\": 0  # Rate 1-10\n",
    "}\n",
    "\n",
    "print(\"üìä Rate yourself from 1-10 in each area:\")\n",
    "print(\"(1 = Beginner, 5 = Intermediate, 10 = Advanced)\\n\")\n",
    "\n",
    "for area, score in assessment_areas.items():\n",
    "    print(f\"{area}: {score}/10\")\n",
    "\n",
    "# Calculate overall readiness\n",
    "total_score = sum(assessment_areas.values())\n",
    "max_score = len(assessment_areas) * 10\n",
    "readiness_percentage = (total_score / max_score) * 100\n",
    "\n",
    "print(f\"\\nüìà Overall Readiness: {total_score}/{max_score} ({readiness_percentage:.1f}%)\")\n",
    "\n",
    "# Readiness interpretation\n",
    "if readiness_percentage >= 80:\n",
    "    status = \"üöÄ Excellent! Ready for advanced topics\"\n",
    "elif readiness_percentage >= 70:\n",
    "    status = \"‚úÖ Good progress! Ready to move forward\"\n",
    "elif readiness_percentage >= 60:\n",
    "    status = \"üìö Adequate foundation. Consider additional practice\"\n",
    "else:\n",
    "    status = \"üí™ Need more practice. Consider review session\"\n",
    "\n",
    "print(f\"Status: {status}\")\n",
    "\n",
    "print(\"\\nüéØ NEXT STEPS RECOMMENDATION:\")\n",
    "if readiness_percentage >= 70:\n",
    "    print(\"‚Ä¢ Ready to proceed to Week 3\")\n",
    "    print(\"‚Ä¢ Focus on advanced prompting techniques\")\n",
    "    print(\"‚Ä¢ Begin specialized testing applications\")\n",
    "else:\n",
    "    print(\"‚Ä¢ Schedule additional review session\")\n",
    "    print(\"‚Ä¢ Practice more basic prompting exercises\")\n",
    "    print(\"‚Ä¢ Clarify fundamental concepts before advancing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Additional Resources & References\n",
    "\n",
    "### Quick Reference Links\n",
    "- [SoftServe AI Learning Hub](https://softserve.csod.com/)\n",
    "- [QMO SharePoint - AI Resources](https://softserveinc.sharepoint.com/sites/QualityManagementOffice/)\n",
    "- [Prompt Engineering Best Practices](https://softserveinc.sharepoint.com/sites/QualityManagementOffice/SitePages/AI-Prompting-for-Software-Testers.aspx)\n",
    "\n",
    "### Emergency Contacts\n",
    "- **Technical Issues:** IT Support\n",
    "- **Content Questions:** Training Coordinator\n",
    "- **Policy Clarifications:** QMO Team\n",
    "\n",
    "### Week 3 Preview\n",
    "Next week we'll focus on:\n",
    "- Advanced prompting frameworks (CRAFT, CLEAR, etc.)\n",
    "- Specialized testing applications\n",
    "- Integration with existing testing workflows\n",
    "- Team collaboration strategies\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ Congratulations on completing Week 2!**  \n",
    "*You've built a solid foundation in GenAI fundamentals and are ready for more advanced applications.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}